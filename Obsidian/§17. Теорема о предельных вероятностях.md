Теорема. Если при некотором $\varepsilon\lt0$ все элементы матрицы перехода $\pi$, положительны, то существуют такие постоянные числа $p_{j}(j=1,2,...,k)$
 что независимо от индекса $i$ имеют место равенства
 $$\operatorname*{lim}_{n\rightarrow\infty}P_{i j}(n)=p_{j}.$$
Доказательство. Идея доказательства этой теоремы весьма проста: сначала устанавливается, что наибольшая из вероятностей $R_{ij}(n)$ с ростом $n$ не может возрастать, а наименьшая не может убывать; далее показывается, что максимум разности $P_{ij}(n)-P_{lj}(n)\ (i,l=1,2,...,k)$ стремиться к нулю, когда $n\to\infty$. Этим доказательство теоремы, очевидно, завершается. Действительно, в силу известной теоремы о пределе монотонной последовательности мы заключаем из первых двух указанных свойств вероятностей $P_{ij}(n)$, что существуют
$$
\operatorname*lim_{n\to\infty}\operatorname*{min}_{1\leq i\leq k}P_{i j}(n) = \bar{p}_{j}
$$
$$
\operatorname*{lim}_{n\to\infty}\operatorname*{max}_{1\leq i\leq k}P_{i j}(n) = \overline{\bar{p}p_{j}}.
$$
А так как в силу третьего из указанных свойств
$$
\operatorname*{lim}_{n\rightarrow\infty}\operatorname*{max}_{1\leq i,l\leq k}\left|P_{ij}(n)-P_{lj}(n)\right| = 0,
$$
$$\overline p_{j} = \overline{\overline p_{j}} = p_{j}$$
Мы перейдем теперь к осуществлению намеченного плана. Заметим прежде всего, что при $n\lt 1$ имеет место неравенство
$$
P_{i j}(n)
=
\sum_{l=1}^{k}p_{il}P_{lj}(n-1)
\geqslant
\operatorname*{min}_{i\leqslant l\leqslant k}P_{ij}(n-1)\sum_{l=1}^{k}p_{il}
=
\operatorname*{min}_{1\leqslant l\leqslant k}P_{i j}(n-1).
$$
Это неравенство имеет место при каждом $i$ в частности при том, при котором 
$$P_{i j}(n)=\operatorname*{min}_{1\leq l\leq k}P_{lj}(n).$$
Таким образом
$$
\operatorname*{min}_{1\leq i\leq k}P_{i j}(n)
\geqslant
\operatorname*{min}_{1\leq i\leq k}P_{i j}(n-1).
$$
Подобным же путем легко обнаружить 
$$
\operatorname*{min}_{1\leq i\leq k}P_{i j}(n)
\leqslant
\operatorname*{min}_{1\leq i\leq k}P_{i j}(n-1).
$$
Мы можем считать, что $n\lt s$ и поэтому имеем право записать по формуле (1) из 16 параграфа, что:
$$P_{i j}(n)=\sum_{r=1}^{k}P_{i r}(s)\cdot P_{r j}(n-s).$$
Рассмотрим разность 
$$
P_{i j}(n)-P_{l j}(n)
=
\sum_{r=1}^{k}P_{i r}(s)\cdot P_{r j}(n-s)-\sum_{r=1}^{k}P_{l r}(s)\cdot P_{r j}(n-s)
=
$$
$$
=
\sum_{r=1}^{k}\left[P_{i r}(s)-P_{l r}(s)\right]P_{r j}(n-s).
$$
Обозначим положительные разности $P_{ir}(s)-P_{lr}(s)$ символом $\beta_{il}^{(r)}$, а неположительные разности — $\beta_{il}^{'(r)}$. Так как 
$$
\sum_{r=1}^{k}P_{ir}(s)
=
\sum_{r=1}^{k}P_{lr}(s)=1,
$$
то 
$$
\sum_{r=1}^{k}\left[P_{i r}(s)-P_{l r}(s)\right]
=
\sum_{(r)}\beta_{il}^{(r)}-\sum_{(r)}\beta_{il}^{'(r)}=0.
$$
Из этого равенства заключаем, что
$$h_{i l}=\sum_{(r)}\beta_{i l}^{(r)}=\sum_{(r)}\beta_{i l}^{'(r)}.$$
Так как по предложению при всех $i$ и $r$ $(i,r=1,2,3,...,k)$ 
то 
$$\sum_{(r)}\beta_{il}^{(r)}\lt \sum_{r=1}^{k}P_{i r}(s)=1.$$
Таким образом,
$$0\leqslant h_{il}\lt 1.$$
Пусть 
$$h=\operatorname*{max}_{l\leq i,l\leq k}h_{il}.$$
Так как число возможных исходов конечно, то наряду с величинами $h_{il}$ величина $h$ удовлетворяет неравенствам 
$$0\leq h\lt1$$
Из (1) находим что при любых $i$ и $l$ $i,l=1,2,...,k$
$$
\left|P_{ij}(n)-P_{lj}(n)\right|
=
\left|\sum_{(r)}\beta_{i l}^{(r)}P_{r j}(n-s)-\sum_{(r)}\beta_{i l}^{'(r)}P_{r j}(n-s)\right|
\leq
$$
$$
\leqslant
\left|\operatorname*{max}_{|\leq r\leq k}P_{r j}(n-s)\sum_{(r)}\beta_{i i}^{(r)}-\operatorname*{min}_{1\leq r\leq k}P_{r j}(n-s)\sum_{(r)}\beta_{i i}^{'(r)}\right|
\leqslant
$$
$$
\leq 
h{\Big|}_{1\leq r\leq k}P_{r j}(n-s)-\operatorname*{min}_{1\leq r\leq k}P_{r j}(n-s){\Big|}
\leqslant
h\operatorname*{max}_{1\leq i\leq k}H_{r j}(n-s)-P_{i j}(n-s){\Big|}
$$
и, следовательно также
$$
\operatorname*{max}_{l\leq i,l\leq k}|P_{ij}(n)-P_{lj}(n)|
\leqslant 
h\operatorname*{max}_{l\leqslant i,l\leqslant k}\left|P_{ij}\left(n-s\right)-P_{lj}\left(n-s\right)\right|.
$$
При этом неравенство $\Big[\frac{n}{s}\Big]$ раз, найдем, что 
$$
\operatorname*{max}_{l\leq i,l\leq k}|P_{ij}(n)-P_{lj}(n)|
\leqslant 
h^{[n/s]}\operatorname*{max}_{l\leqslant i,l\leqslant k}\left|P_{ij}\left(n-\left[ {\frac{n}{s}}\right]s\right)-P_{lj}\left(n-\left[{\frac{n}{s}}\right]s\right)\right|.
$$
Так как всегда $\left|P_{ij}(m)-P_{lj}(m)\right|\leqslant1$, то ясно, что 
$$
\operatorname*{max}_{l\leqslant i,l\leq k}\left|P_{ij}(n)-P_{lj}(n)\right|\leqslant h^{[n/s]}.
$$
При $n\to\infty$ также $\Big[\frac{n}{s}\Big]\to\infty,$ поэтому в силу (3) отсюда следует, что 
$$
\operatorname*{lim}_{n\to\infty}\operatorname*{max}_{l\leq i, l\leq k}\left|P_{ij}(n)-P_{lj}(n)\right|=0.
$$
Из доказанного заключаем также, что 
$$\sum\limits_{j=1}^{k}p_{j}=1$$
Действительно
$$
\sum_{j=1}^{k}p_{j}
=
\operatorname*{lim}_{n\to\infty}\sum_{j=1}^{k}P_{i j}(n)
=
\operatorname*{lim}_{n\to\infty}1=1.
$$
Таким образом, на величины $p_{j}$ можно смотреть как на вероятности появления исхода $A_{j}^{(n)}$ при $n$-м испытании, когда $n$ велико.
Физический смысл доказанной теоремы ясен: вероятность системе находиться в состоянии $A_{j}$- практически не зависит от того, в каком состоянии она находилась в далеком прошлом.
Только что обнаруженная теорема была впервые докаина творцом теории цепных зависимостей А. А. Марковым; она явилась первым строго доказанным результатом среди так называемых эргодических теорем, играющих важную роль в современной физике и инженерном деле.